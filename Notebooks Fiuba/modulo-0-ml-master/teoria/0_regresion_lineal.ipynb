{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTACYONzkO5b",
    "tags": []
   },
   "source": [
    "# Regresión Lineal\n",
    "\n",
    "$y=a+bx+\\epsilon$\n",
    "\n",
    "El modelo de regresión lineal asume que la relación entre una variable continua dependiente $y$ y una o más variables explicativas (independientes) $X$ es lineal (es decir, que lo podemos modelizar con una línea recta). \n",
    "\n",
    "Se utiliza para predecir valores dentro de un rango continuo (por ejemplo, cantidad de ventas, el precio en función de otras variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/regresion_lineal.jpeg\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "Fuente: http://mybooksucks.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediciendo la presión sanguinea a partir de la edad..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos datos de medición de la presión sanguínea sistólica (medida en mm de Mercurio) para 29 personas de diferentes edades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('datasets/regresion/precio_viviendas.csv')\n",
    "\n",
    "df = pd.read_csv('datasets/regresion/edad_presion.csv', skiprows=32, usecols=[2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Age': 'edad', 'Systolic blood pressure': 'presion'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a intentar predecir el precio de venta (SalePrice) en función de la cantidad de superficie habitable (en pies cuadrados) (GrLivArea)\n",
    "\n",
    "# df = df[['GrLivArea', 'SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['edad'], df['presion'], alpha=0.2, edgecolor='black')\n",
    "plt.xlabel('edad')\n",
    "plt.ylabel('presion');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### División del dataset en conjunto de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entrenar cualquier modelo de aprendizaje automático, independientemente del tipo de conjunto de datos que se esté utilizando, debemos dividir el conjunto de datos en datos de entrenamiento y datos de prueba y datos de validación. Pero, ¿por qué?\n",
    "\n",
    "Entrenar un modelo de aprendizaje automático supervisado es conceptualmente muy simple e implica el siguiente proceso de tres pasos:\n",
    "\n",
    "**1. Enviar muestras del conjunto de datos a un modelo (inicializado)**: las muestras de su conjunto de datos se transmiten a través del modelo, lo que genera predicciones.\n",
    "\n",
    "**2. Comparar predicciones y verdad fundamental**: las predicciones se comparan con las etiquetas verdaderas correspondientes a las muestras, lo que nos permite identificar qué tan mal funciona el modelo.\n",
    "\n",
    "**3. Loop de mejora**: basándonos en la métrica de optimización, podemos cambiar las partes internas del modelo aquí y allá, para que (con suerte) funcione mejor durante la próxima iteración.\n",
    "\n",
    "\n",
    "Cuando continúe realizando estas iteraciones, el modelo continuará mejorando, porque puede \"explotar\" todos los patrones espurios en su conjunto de datos.\n",
    "Pero, ¿qué pasa si esos patrones espurios no están presentes en los datos del mundo real para los que generará predicciones después del entrenamiento? ¿Qué sucede si, por lo tanto, el modelo se entrena en patrones que son exclusivos del conjunto de datos de entrenamiento y no están presentes en el conjunto de datos para la inferencia ?\n",
    "\n",
    "Entonces, dicho brevemente, tiene un problema.\n",
    "\n",
    "\n",
    "\n",
    "* **Conjunto de entrenamiento (train set)**: es el conjunto de datos utilizados para el aprendizaje del modelo, es decir, para ajustar los hiperparámetros al modelo de aprendizaje automático.\n",
    "\n",
    "* **Conjunto de datos de prueba (test set)**: es el conjunto de datos utilizados para proporcionar una evaluación imparcial del modelo final ajustado en el conjunto de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/split_dataset.webp\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.20, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax1.scatter(df_train['edad'], df_train['presion'], alpha=0.2, edgecolor='black')\n",
    "ax1.set_ylabel('presion')\n",
    "ax1.set_xlabel('edad')\n",
    "ax1.set_title('Datos de entrenamiento')\n",
    "ax2.scatter(df_test['edad'], df_test['presion'], alpha=0.2, edgecolor='black')\n",
    "ax2.set_ylabel('presion')\n",
    "ax2.set_xlabel('edad')\n",
    "ax2.set_title('Datos de validación');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6_tlsxdtGvU"
   },
   "source": [
    "# Pseudoinversa\n",
    "\n",
    "Matrices que no tienen inversa:\n",
    "  * det = 0\n",
    "  * No cuadradas\n",
    "\n",
    "$Y = aX$\n",
    "\n",
    "Si quiero obtener el $a$ que minimiza el error cuadrático medio utilizando la pseudoinversa, simplemente\n",
    "\n",
    "$\\hat{a} = (X^T X)^{-1} X^T Y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-_U6OB2zLLG"
   },
   "source": [
    "En nuestro caso,\n",
    "\n",
    "Aunque a priori, parece que solo hay un predictor ($ x_1 $), nuestro modelo requiere un segundo (llamémoslo $ x_0 $) para permitir una intercepción con $ y $. Sin esta segunda variable, la línea que ajustamos a la gráfica tendría que pasar por el origen (0, 0). La intersección $ y $ es constante en todos los puntos, por lo que podemos establecerla igual a 1 en todos los ámbitos:\n",
    "\n",
    "$Y = a + bX = \\left[\\mathbf{1}; X\\right] \\begin{bmatrix} a \\\\ b\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Para nuestro ejemplo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((np.ones_like(df_train['edad']), df_train['edad'])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y = a + bX\n",
    "a, b = np.dot(np.linalg.pinv(X), df_train['presion'])\n",
    "print(f\"Solución por pseudoinversa (Y=a+bX) => a={a}  |  b={b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Datos de entrenamiento\n",
    "ax1.scatter(df_train['edad'], df_train['presion'], alpha=0.2, edgecolor='black')\n",
    "ax1.set_ylabel('presion')\n",
    "ax1.set_xlabel('edad')\n",
    "ax1.set_title('Datos de entrenamiento')\n",
    "\n",
    "x1_min, x1_max = ax1.get_xlim()\n",
    "y_at_xmin1 = b * x1_min + a\n",
    "y_at_xmax1 = b * x1_max + a\n",
    "ax1.set_xlim([x1_min, x1_max])\n",
    "_ = ax1.plot([x1_min, x1_max], [y_at_xmin1, y_at_xmax1], c='green')\n",
    "\n",
    "\n",
    "# Datos de test\n",
    "ax2.scatter(df_test['edad'], df_test['presion'], alpha=0.2, edgecolor='black')\n",
    "ax2.set_ylabel('presion')\n",
    "ax2.set_xlabel('edad')\n",
    "ax2.set_title('Datos de validación')\n",
    "\n",
    "x2_min, x2_max = ax2.get_xlim()\n",
    "y_at_xmin2 = b * x2_min + a\n",
    "y_at_xmax2 = b * x2_max + a\n",
    "ax2.set_xlim([x2_min, x2_max])\n",
    "_ = ax2.plot([x2_min, x2_max], [y_at_xmin2, y_at_xmax2], c='green');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1633989592699,
     "user": {
      "displayName": "ANA LAURA VADNJAL",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15895729588619935366"
     },
     "user_tz": 180
    },
    "id": "NJ6aRNmj3RP2",
    "outputId": "d5bced4a-123b-408c-99ae-3b0d36bb7a45"
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_test['edad'], df_test['presion'], alpha=0.2, edgecolor='black')\n",
    "x_sol = np.arange(0, 1.1, .1)\n",
    "y_sol = a + b * x_sol\n",
    "plt.plot(x_sol, y_sol, 'r')\n",
    "plt.xlabel('edad')\n",
    "plt.ylabel('presion')\n",
    "plt.title('Distancia a la predicción')\n",
    "for x, y in zip(df_test['edad'], df_test['presion']):\n",
    "    y_pred = a + b * x\n",
    "    plt.plot([x, x], [y, y_pred], 'k', alpha=0.8)\n",
    "\n",
    "# Predicción de los valores de validación\n",
    "yhat = a + df_test['edad'] * b\n",
    "print('ECM por pseudoinversa:', np.mean((yhat - df_test['presion'])**2))\n",
    "\n",
    "x_min, x_max = plt.xlim()\n",
    "y_at_xmin = b * x_min + a\n",
    "y_at_xmax = b * x_max + a\n",
    "plt.xlim([x_min, x_max])\n",
    "plt.plot([x_min, x_max], [y_at_xmin, y_at_xmax], c='green');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Gradiente descendente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/descenso_gradiente_ilustracion.jpeg\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zytpoJUXHopG"
   },
   "source": [
    "\n",
    "\n",
    "* Inicialización de los parámetros $a$ y $b$\n",
    "* Definición de los hiperparámetros $\\eta$ (constante de aprendizaje) y número de epochs (cantidad de iteraciones de entrenamiento)\n",
    "* Iniciar loop de pasos del 1 al 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkzyPafGnvzZ",
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "1. Computar función de costo, ej.: ECM\n",
    "\n",
    "\\begin{equation} \n",
    "ECM = \\frac{1}{N}\\sum_i^N (y_i - \\hat{y}_i)^2 \\\\\n",
    "ECM = \\frac{1}{N}\\sum_i^N (y_i - a - bx_i)^2\n",
    "\\end{equation}\n",
    "\n",
    "2. Computar gradientes\n",
    "\n",
    "\\begin{equation} \n",
    "\\frac{\\partial ECM}{\\partial a} = \\frac{1}{N}\\sum_i^N 2(y_i - a - bx_i)(-1) = -2\\frac{1}{N}\\sum_i^N (y_i - \\hat{y}_i) \\\\\n",
    "\\frac{\\partial ECM}{\\partial b} = \\frac{1}{N}\\sum_i^N 2(y_i - a - bx_i)(-x_i) = -2\\frac{1}{N}\\sum_i^N x_i(y_i - \\hat{y}_i)\n",
    "\\end{equation}\n",
    "\n",
    "3. Actualizar parámetros\n",
    "\n",
    "\\begin{equation} \n",
    "a = a - \\eta \\frac{\\partial ECM}{\\partial a}  \\\\\n",
    "b = b - \\eta \\frac{\\partial ECM}{\\partial b}\n",
    "\\end{equation}\n",
    "\n",
    "4. Volver al paso 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A tener en cuenta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tenemos una red con solo 2 parámetros, podemos representar la función de coste en 3 dimensiones (los parámetros en el plano xy, y el coste en el plano z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/curva_ideal.png\" alt=\"Drawing\" style=\"width: 350px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero probablemente vamos a tener millones de parámetros, ademas de tener minimos locales que durante el entrenamiento pueden confundirse con el mínimo global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/curva_real.png\" alt=\"Drawing\" style=\"width: 350px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La elección de la tasa de aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El valor no deberia ser ni muy grande (posibles oscilaciones) ni muy chico (lento, mas iteraciones, sobreajuste) \n",
    "* Fija o variable en el tiempo.\n",
    "* La misma para toda la red o varia por capa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/learning_rate.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upoyglrsJv2t",
    "tags": []
   },
   "source": [
    "## Usando numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train['edad'].values\n",
    "y_train = df_train['presion'].values\n",
    "\n",
    "x_test = df_test['edad'].values\n",
    "y_test = df_test['presion'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_error(y, yhat):\n",
    "    error = np.sum((y - yhat)**2) / len(y)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1633989592700,
     "user": {
      "displayName": "ANA LAURA VADNJAL",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15895729588619935366"
     },
     "user_tz": 180
    },
    "id": "7hU35UNqIU8E",
    "outputId": "d9b9a731-1b3b-43b1-cecf-8f3be53a36c7"
   },
   "outputs": [],
   "source": [
    "# Iniciar parámetros a y b\n",
    "np.random.seed(42)\n",
    "\n",
    "a = np.random.randn(1)\n",
    "b = np.random.randn(1)\n",
    "\n",
    "print('a y b iniciales:', a, b)\n",
    "\n",
    "lr = 0.0001         # constante de aprendizaje\n",
    "n_epochs = 1000   # número de iteraciones\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Computar predicción del modelo\n",
    "    yhat = a + b * x_train\n",
    "    \n",
    "    # Calcular error cuadrático medio (ECM)\n",
    "    error = (y_train - yhat)\n",
    "    loss = (error ** 2).mean()\n",
    "    \n",
    "    # Computar gradiente\n",
    "    a_grad = -2 * error.mean()\n",
    "    b_grad = -2 * (x_train * error).mean()\n",
    "    \n",
    "    # Actualizar parámetros\n",
    "    a = a - (lr * a_grad)\n",
    "    b = b - (lr * b_grad)\n",
    "\n",
    "# Computar predicción final\n",
    "yhat = a + b * x_train\n",
    "# Calcular ECM final\n",
    "error = (y_train - yhat)\n",
    "loss = (error ** 2).mean()\n",
    "\n",
    "print('a y b finales:', a, b)\n",
    "print('ECM por gradiente descendente:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKZQgUzoLEOk"
   },
   "source": [
    "## Pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14766,
     "status": "ok",
     "timestamp": 1633989645310,
     "user": {
      "displayName": "ANA LAURA VADNJAL",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15895729588619935366"
     },
     "user_tz": 180
    },
    "id": "3KNB6KW6LLFw",
    "outputId": "d8b62624-9764-4444-d1d1-cc688ca71c55"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Convertir los arrays de numpy a tensores de pytorch, castearlos a float y \n",
    "# alojarlos en el dispositivo disponible\n",
    "x_train_tensor = torch.from_numpy(x_train).float().to(device)\n",
    "y_train_tensor = torch.from_numpy(y_train).float().to(device)\n",
    "\n",
    "print(type(x_train), type(x_train_tensor), x_train_tensor.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "executionInfo": {
     "elapsed": 374,
     "status": "error",
     "timestamp": 1633989767064,
     "user": {
      "displayName": "ANA LAURA VADNJAL",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15895729588619935366"
     },
     "user_tz": 180
    },
    "id": "og-tOTd5YJg9",
    "outputId": "ad605365-9256-4431-ef2d-3a8b8e02fe6c"
   },
   "outputs": [],
   "source": [
    "# Se puede volver a convertir el tensor de pytorch a numpy\n",
    "x_train_tensor_numpy = x_train_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HINogtLSYSkJ"
   },
   "outputs": [],
   "source": [
    "# Pero primero hay que alojarlo en cpu\n",
    "x_train_tensor_numpy = x_train_tensor.to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhJj4O76Zlej"
   },
   "source": [
    "Los tensores de datos no son como ```x_train``` e ```y_train``` no son variables entrenables, pero sí lo son ```a``` y ```b```, y para esto nos sirve ```requires_grad=True```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1633990831109,
     "user": {
      "displayName": "ANA LAURA VADNJAL",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15895729588619935366"
     },
     "user_tz": 180
    },
    "id": "CyGLr17gYcn2",
    "outputId": "2319c3bf-93c3-4b75-b5f9-3cfb8eb63f94"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "# Para el algoritmo gradiente descendente necesitamos calcular el gradiente de \n",
    "# los parámetros\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "print(a, b)\n",
    "\n",
    "# En GPU\n",
    "a = torch.randn(1, dtype=torch.float).to(device)\n",
    "b = torch.randn(1, dtype=torch.float).to(device)\n",
    "a.requires_grad_()\n",
    "b.requires_grad_()\n",
    "print(a, b)\n",
    "\n",
    "# Otra opción\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dfqGxwLcueC"
   },
   "source": [
    "## Gradiente descendente con Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 960,
     "status": "ok",
     "timestamp": 1633992546910,
     "user": {
      "displayName": "ANA LAURA VADNJAL",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "15895729588619935366"
     },
     "user_tz": 180
    },
    "id": "OJV02Kz4cM5c",
    "outputId": "c4c272ad-fee0-4a57-9f2f-17d6fdea0fc4"
   },
   "outputs": [],
   "source": [
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "print('a y b iniciales:', a, b)\n",
    "\n",
    "# Elegir el algoritmo de optimización, en este caso Stochastic Gradient Descent\n",
    "optimizer = optim.SGD([a, b], lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    yhat = a + b * x_train_tensor\n",
    "    error = y_train_tensor - yhat\n",
    "    loss = (error ** 2).mean()\n",
    "    \n",
    "    # el método backward() aplicado a la función de costo calcula los gradientes \n",
    "    # de los parámetros\n",
    "    loss.backward()\n",
    "\n",
    "    # actualizar parámetros\n",
    "    optimizer.step()\n",
    "\n",
    "    # limpiar el cálculo de los gradientes para que no acumule\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print('a y b finales:', a, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNs/v1LwxmCquKjWcfDr8wo",
   "name": "autograd.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
