{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec5bfa7-a780-4e9a-a6e9-f596d250bf1f",
   "metadata": {},
   "source": [
    "# Clasificación de textos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6613124-6c84-496e-846c-0682bc44cf7a",
   "metadata": {},
   "source": [
    "<img src=\"images/text_classification.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff640fc-fc8f-448f-8272-ed25b98aaa03",
   "metadata": {},
   "source": [
    "<img src=\"images/sentiment_analysis.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2af0e4-5e80-4647-bd0e-88d9b5186e2c",
   "metadata": {},
   "source": [
    "# Corpus, Vocabulario y extracción de características"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89936212-c630-491b-b4ac-eae883437e81",
   "metadata": {},
   "source": [
    "# CORPUS: todo el conjunto de frases\n",
    "\n",
    "[\n",
    "    \"me gusta aprender procesamiento de lenguaje natural\",\n",
    "    \"el procesamiento de lenguaje natural no me gusta pero me resulta dificil\",\n",
    "    ....,\n",
    "    ....,\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e6ae09f-f5cd-4647-877b-4bf19633724e",
   "metadata": {},
   "source": [
    "# VOCABULARIO: conjunto de palabras únicas utilizadas en el corpus (también existen vocabularios basados en caracteres)\n",
    "\n",
    "V = [me, gusta, aprender, procesamiento, de, lenguaje, natural, el, no, y, resulta, dificil]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76b50e20-92f6-4daf-80a4-c02e8182cbc3",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "\n",
    "[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
    "[1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a4f1a3-1f8e-4352-ae87-bf39a7f1e95a",
   "metadata": {},
   "source": [
    "En un dataset grande (no tanto), lleva a un representacion sparse (muchos ceros)!! Y esto lleva al problema:\n",
    "\n",
    "    - Mayor tiempo de entrenamiento.\n",
    "    - Mayor tiempo para hacer una predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25cc4f6-b34f-4300-a2ef-c69d92ae0213",
   "metadata": {},
   "source": [
    "#### Aplicación de métodos probabilísticos (Naive Bayes, suavizado laplaciano, etc)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5968d5d-3a42-46f5-80e0-27086adb27fb",
   "metadata": {},
   "source": [
    "[\n",
    "    \"me gusta aprender procesamiento de lenguaje natural\",                         # POS\n",
    "    \"el procesamiento de lenguaje natural no me gusta y me resulta dificil\",       # NEG\n",
    "    \"me gusta\",                                                                    # POS\n",
    "    \"no me gusta\"                                                                  # NEG\n",
    "    ....,\n",
    "    ....,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203e0dae-4c26-44b7-b259-131d1bb566bd",
   "metadata": {},
   "source": [
    "<img src=\"images/probs.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5240fd2-2159-4e4b-ab31-ccbd6b00cafd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tokenización (Tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c0a020-4f66-48e1-9287-46835c114b07",
   "metadata": {},
   "source": [
    "La tokenización no es mas que separar un texto en unidades mas pequeñas: palabras, subpalabras o caracteres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0dbb81-8031-4a90-996c-238ce0e9a74e",
   "metadata": {},
   "source": [
    "### Tokenización en palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0af6aa8-62c0-4c2c-bc60-4f83ba259838",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"el machine learning es una rama de estudio de la inteligencia artificial. artificiale es nnn\"\n",
    "\n",
    "token = 'xxtokenraroxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "babc5f33-3d42-4de3-8588-b976d8f3b3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['el',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'es',\n",
       " 'una',\n",
       " 'rama',\n",
       " 'de',\n",
       " 'estudio',\n",
       " 'de',\n",
       " 'la',\n",
       " 'inteligencia',\n",
       " 'artificial.',\n",
       " 'artificiale',\n",
       " 'es',\n",
       " 'nnn']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d8bdf7-2719-4245-b308-029a3b6381bc",
   "metadata": {},
   "source": [
    "**El principal problema es el manejo de palabras fuera del vocabulario. ¿Entonces?**\n",
    "\n",
    "    - Se puede resolver armando un top de palabras mas frecuentes y tokenizar las palabras mas raras con otro token (el problema acá es que cada palabra \"rara\" tendra la misma representacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707b0a23-8e42-4a8a-b33f-9ec4f57cadb6",
   "metadata": {},
   "source": [
    "### Tokenización en caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7397c095-633b-40c4-bb35-514ef2b3c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"maquina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5565e17-3224-4623-981e-25cb9c3758a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m', 'a', 'q', 'u', 'i', 'n', 'a']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0d83cf-780e-4f77-8e94-e0895410b185",
   "metadata": {},
   "source": [
    "El texto se descompone en caracteres, se limita el tamaño del vocabulario.\n",
    "\n",
    "El principal problema que tiene:\n",
    "\n",
    "    - Es mas dificil aprender relaciones entre caracteres para formar frases significativas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05540c13-1463-4e5a-872a-cbfc729f36ee",
   "metadata": {},
   "source": [
    "### Tokenización en subpalabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acba6a99-7ef7-4828-b815-01a9ee2f5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"maquina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f34dc629-8f7f-4f86-8ec0-5a124255182a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ma', 'qui', 'na']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"ma\", \"qui\", \"na\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b61f9f2f-d07c-49bc-a2b6-674183a11b18",
   "metadata": {},
   "source": [
    "[\n",
    "    \"me gusta aprender procesamiento de lenguaje natural\",                         # POS\n",
    "    \"el procesamiento de lenguaje natural no me gusta y me resulta dificil\",       # NEG\n",
    "    \"me gusta\",                                                                    # POS\n",
    "    \"no me gusta\"                                                                  # NEG\n",
    "    ....,\n",
    "    ....,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e4fa8d-3d11-483d-84bb-2da4b271f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "text = \"\"\"me gusta aprender procesamiento de lenguaje natural.\"\"\"\n",
    "doc = nlp(text) # Crea un objeto de spacy tipo nlp\n",
    "tokens = [t.orth_ for t in doc] # Crea una lista con las palabras del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fcaec1f-01a7-4af7-aa1e-696b269db6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['me', 'gusta', 'aprender', 'procesamiento', 'de', 'lenguaje', 'natural', '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18183e7e-7d59-4137-a646-cbb0b9b7f14e",
   "metadata": {},
   "source": [
    "# Stemming & Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49749ca3-0245-4700-ab06-d9d6f45aefaa",
   "metadata": {},
   "source": [
    "* El ***stemming*** es quitar y reemplazar los sufijos de la raiz de la palabra; llevarla a su raíz.\n",
    "* El resultado no tiene por que ser una palabra de un idioma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0297b249-b9d8-4907-a1c2-149d4f863366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f50109b0-d41f-4bfe-92c4-be0d8dffe23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "\n",
    "text = \"\"\"Esta es una oración y debe ser procesada o procesado a la brevedad. Cantar, bailar y escribir. Cantó, bailó y escribió.\"\"\"\n",
    "\n",
    "tokens = text.split(' ')\n",
    "\n",
    "stems = [stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21857f23-78cc-44c3-8b50-9dac1a594c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['esta',\n",
       " 'es',\n",
       " 'una',\n",
       " 'oracion',\n",
       " 'y',\n",
       " 'deb',\n",
       " 'ser',\n",
       " 'proces',\n",
       " 'o',\n",
       " 'proces',\n",
       " 'a',\n",
       " 'la',\n",
       " 'brevedad.',\n",
       " 'cantar,',\n",
       " 'bail',\n",
       " 'y',\n",
       " 'escribir.',\n",
       " 'canto,',\n",
       " 'bail',\n",
       " 'y',\n",
       " 'escribio.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25505d3-83c8-4fce-95bd-400f2ee28075",
   "metadata": {},
   "source": [
    "* La ***lemmatizacion*** es llevar una palabra a su forma canónica.\n",
    "* Ejemplo: escribe -> escribir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0acdc42-e51f-430e-a5c2-ea31a2d4bd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "text = \"\"\"Esta es una oración y debe ser procesada a la brevedad. Cantar, bailar y escribir. Cantó, bailó y escribió.\"\"\"\n",
    "doc = nlp(text)\n",
    "lemmas = [tok.lemma_.lower() for tok in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c7c8b48-c626-46ba-a7d5-b8de8387a81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['este',\n",
       " 'ser',\n",
       " 'uno',\n",
       " 'oración',\n",
       " 'y',\n",
       " 'deber',\n",
       " 'ser',\n",
       " 'procesar',\n",
       " 'a',\n",
       " 'el',\n",
       " 'brevedad',\n",
       " '.',\n",
       " 'cantar',\n",
       " ',',\n",
       " 'bailar',\n",
       " 'y',\n",
       " 'escribir',\n",
       " '.',\n",
       " 'cantó',\n",
       " ',',\n",
       " 'bailar',\n",
       " 'y',\n",
       " 'escribir',\n",
       " '.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e4894f-c702-467d-ac62-a9ccdc6c272d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
